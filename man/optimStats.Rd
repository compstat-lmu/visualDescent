% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim.fromStats.R
\name{optimStats}
\alias{optimStats}
\title{Optimize mathematical function using gradient descent}
\usage{
optimStats(
  f,
  x0,
  max.iter = 100,
  method = "Nelder-Mead",
  stop.grad = .Machine$double.eps
)
}
\arguments{
\item{f}{a (multi-) dimensional function to be eptimized.}

\item{x0}{the starting point of the optimization.}

\item{max.iter}{the maximum number of iterations performed in the optimization.}

\item{stop.grad}{the stop-criterion for the gradient change.}

\item{step.size}{the step size (sometimes referred to as 'learn-rate') of the optimization.}
}
\description{
This functions uses the gradient descent algorithm to find the minimum of a
(multi-) dimensional mathematical function.
}
